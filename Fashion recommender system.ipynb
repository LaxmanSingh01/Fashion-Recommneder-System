{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a07b69ef",
   "metadata": {},
   "source": [
    "## Building Fashion Recommendation Systems\n",
    "- Businesses such as Spotify and Netflix have been trailblazers in the recommendation systems world. More than 80% of the TV shows people watch on Netflix are discovered through the platform’s recommendation system (Wired) and Discover Weekly playlists boasted 40 million unique users just a year after it launched in July 2015 (TechCrunch).\n",
    "\n",
    "- In contrast, the fashion industry has been relatively slow on the uptake when it comes to robust recommendation systems, but for good reason."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc86e8e",
   "metadata": {},
   "source": [
    "## Method to build Fashion Recommmeder System\n",
    "#### Basically our model is based on the method of reverse image search.\n",
    "For example : If an user upload a image of product on site , then our model recommends 5 more products related to that product by comapring the feature of that product with other.\n",
    "\n",
    "#### we are going to use transferlearning(Resnet50) technique for extracting the feature of product\n",
    "- Step 1 - We are going to import the resnet50 model\n",
    "- Step2 - We are going to extract the features of products with the help of resnet50\n",
    "- Step3 - Export the features (we are going to save that extracted features somewhere(like list) to repeatedly use them)\n",
    "- Step 4 - We are going to recommnend the products related to the uploaded product..(with the help of Nearest Neighbour Algorithm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37eb0e8",
   "metadata": {},
   "source": [
    "## Lets import all the required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "778f4694",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.preprocessing import image ## for loading the image\n",
    "from tensorflow.keras.layers import GlobalMaxPooling2D\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50,preprocess_input\n",
    "import numpy as np\n",
    "from numpy.linalg import norm ## for naormalizing the features\n",
    "import os\n",
    "from tqdm import tqdm ## for checking the process of the for loop.\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f01beb2",
   "metadata": {},
   "source": [
    "## Initializing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "214e2656",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ResNet50(include_top=False,weights='imagenet',input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d621c25",
   "metadata": {},
   "source": [
    "#### As we know resnet50 is already trained on imagenet dataset with very good accuracy, so we don't need to train it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1123dd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.trainable=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bf5fc0",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a39fbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tensorflow.keras.Sequential([model,GlobalMaxPooling2D()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4904f990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Functional)        (None, 7, 7, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d (Global (None, 2048)              0         \n",
      "=================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 0\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Lets see our model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826c246b",
   "metadata": {},
   "source": [
    "#### we can see that resnet50 returns 2048 features of one image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db685881",
   "metadata": {},
   "source": [
    "## Now we are going to extract the features from resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d373fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(image_path,model):\n",
    "    ## we have to load the image first\n",
    "    img=image.load_img(image_path,target_size=(224,224))\n",
    "    ## Converting the image into array\n",
    "    image_array=image.img_to_array(img)\n",
    "    ## Now expanding the dimension of image (as we know the image with batch size is only accepted by resnet50)\n",
    "    expanded_img=np.expand_dims(image_array,axis=0)\n",
    "    ## Now we are going to preprocess the image\n",
    "    img_preprocessed=preprocess_input(expanded_img)\n",
    "    ## Now we are going to take predictions from the mode;\n",
    "    predictions=model.predict(img_preprocessed).flatten()\n",
    "    ## Now we are going to normalize the image (Just to scale down the image)\n",
    "    prediction_normalized= predictions/norm(predictions)\n",
    "    return prediction_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92da7baa",
   "metadata": {},
   "source": [
    "#### Now we have to store the all the image path in one list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de0681ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44441\n"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir('images')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b074b6",
   "metadata": {},
   "source": [
    "#### we can see that we have 44k images in our datastet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "489da6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = []\n",
    "for i in os.listdir('images'):\n",
    "    file.append(os.path.join('images',i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e69c0a1",
   "metadata": {},
   "source": [
    "#### we have all the paths of our iamges in our file list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361dbd5e",
   "metadata": {},
   "source": [
    "#### Now we have to pass image_path one by one to our extract_feature method to extract the feature and going to save these features in a list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f045bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 44441/44441 [3:31:16<00:00,  3.51it/s]\n"
     ]
    }
   ],
   "source": [
    "features_list=[]\n",
    "for i in tqdm(file):\n",
    "    features_list.append(extract_features(i,model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f9aec77",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(features_list,open('feature.pkl','wb'))\n",
    "pickle.dump(file,open('file_name.pkl','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
